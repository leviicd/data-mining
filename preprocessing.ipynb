{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNK5cgB8f1u+a25voMCZS8G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leviicd/data-mining/blob/main/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M08Nn2sVFtMx",
        "outputId": "d5f274d4-e33e-4cbb-dd36-7112496923ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Awal (beberapa baris pertama):\n",
            "   CLASS  AGE  SEX  STEROID  ANTIVIRALS  FATIGUE  MALAISE  ANOREXIA  \\\n",
            "0      2   30    2      1.0           2      2.0      2.0       2.0   \n",
            "1      2   50    1      1.0           2      1.0      2.0       2.0   \n",
            "2      2   78    1      2.0           2      1.0      2.0       2.0   \n",
            "3      2   31    1      NaN           1      2.0      2.0       2.0   \n",
            "4      2   34    1      2.0           2      2.0      2.0       2.0   \n",
            "\n",
            "   LIVER_BIG  LIVER_FIRM  SPLEEN_PALPABLE  SPIDERS  ASCITES  VARICES  \\\n",
            "0        1.0         2.0              2.0      2.0      2.0      2.0   \n",
            "1        1.0         2.0              2.0      2.0      2.0      2.0   \n",
            "2        2.0         2.0              2.0      2.0      2.0      2.0   \n",
            "3        2.0         2.0              2.0      2.0      2.0      2.0   \n",
            "4        2.0         2.0              2.0      2.0      2.0      2.0   \n",
            "\n",
            "   BILIRUBIN  ALK_PHOSPHATE   SGOT  ALBUMIN  PROTIME  HISTOLOGY  \n",
            "0        1.0           85.0   18.0      4.0      NaN          1  \n",
            "1        0.9          135.0   42.0      3.5      NaN          1  \n",
            "2        0.7           96.0   32.0      4.0      NaN          1  \n",
            "3        0.7           46.0   52.0      4.0     80.0          1  \n",
            "4        1.0            NaN  200.0      4.0      NaN          1  \n",
            "\n",
            "Info Dataset Awal:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 155 entries, 0 to 154\n",
            "Data columns (total 20 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   CLASS            155 non-null    int64  \n",
            " 1   AGE              155 non-null    int64  \n",
            " 2   SEX              155 non-null    int64  \n",
            " 3   STEROID          154 non-null    float64\n",
            " 4   ANTIVIRALS       155 non-null    int64  \n",
            " 5   FATIGUE          154 non-null    float64\n",
            " 6   MALAISE          154 non-null    float64\n",
            " 7   ANOREXIA         154 non-null    float64\n",
            " 8   LIVER_BIG        145 non-null    float64\n",
            " 9   LIVER_FIRM       144 non-null    float64\n",
            " 10  SPLEEN_PALPABLE  150 non-null    float64\n",
            " 11  SPIDERS          150 non-null    float64\n",
            " 12  ASCITES          150 non-null    float64\n",
            " 13  VARICES          150 non-null    float64\n",
            " 14  BILIRUBIN        149 non-null    float64\n",
            " 15  ALK_PHOSPHATE    126 non-null    float64\n",
            " 16  SGOT             151 non-null    float64\n",
            " 17  ALBUMIN          139 non-null    float64\n",
            " 18  PROTIME          88 non-null     float64\n",
            " 19  HISTOLOGY        155 non-null    int64  \n",
            "dtypes: float64(15), int64(5)\n",
            "memory usage: 24.3 KB\n",
            "\n",
            "================ HASIL PREPROCESSING ================\n",
            "Bentuk X_train: (124, 32)\n",
            "Bentuk X_test: (31, 32)\n",
            "Bentuk y_train: (124,)\n",
            "Bentuk y_test: (31,)\n",
            "\n",
            "Contoh data X_train setelah preprocessing:\n",
            "[[-8.94191753e-01 -5.29790681e-01  9.00962493e-01  4.77429436e-01\n",
            "   1.34579695e-01  2.22591800e+00  1.00000000e+00  0.00000000e+00\n",
            "   1.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00\n",
            "   1.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  1.00000000e+00  0.00000000e+00  1.00000000e+00\n",
            "   1.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00\n",
            "   1.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00\n",
            "   0.00000000e+00  1.00000000e+00  0.00000000e+00  1.00000000e+00]\n",
            " [ 6.38708395e-02  6.11950733e-02 -4.39414387e-01 -5.20381565e-01\n",
            "   0.00000000e+00 -4.14601335e-16  1.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  1.00000000e+00  0.00000000e+00  1.00000000e+00\n",
            "   0.00000000e+00  1.00000000e+00  0.00000000e+00  1.00000000e+00\n",
            "   0.00000000e+00  1.00000000e+00  0.00000000e+00  1.00000000e+00\n",
            "   0.00000000e+00  1.00000000e+00  1.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  1.00000000e+00  0.00000000e+00  1.00000000e+00\n",
            "   0.00000000e+00  1.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
            "\n",
            "Contoh data y_train setelah encoding:\n",
            "[1 1 1 0 1 1 1 1 0 1]\n",
            "===================================================\n"
          ]
        }
      ],
      "source": [
        "# Langkah 1: Import Library yang Dibutuhkan\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline # Import Pipeline\n",
        "\n",
        "# Langkah 2: Memuat Dataset dan Memberi Nama Kolom\n",
        "# Berdasarkan file hepatitis.names, kita buat daftar nama kolom\n",
        "column_names = [\n",
        "    'CLASS', 'AGE', 'SEX', 'STEROID', 'ANTIVIRALS', 'FATIGUE', 'MALAISE',\n",
        "    'ANOREXIA', 'LIVER_BIG', 'LIVER_FIRM', 'SPLEEN_PALPABLE', 'SPIDERS',\n",
        "    'ASCITES', 'VARICES', 'BILIRUBIN', 'ALK_PHOSPHATE', 'SGOT', 'ALBUMIN',\n",
        "    'PROTIME', 'HISTOLOGY'\n",
        "]\n",
        "\n",
        "# Membaca data, karena tidak ada header dan missing values ditandai '?'\n",
        "dataset = pd.read_csv('hepatitis.data', header=None, names=column_names, na_values='?')\n",
        "print(\"Dataset Awal (beberapa baris pertama):\")\n",
        "print(dataset.head())\n",
        "print(\"\\nInfo Dataset Awal:\")\n",
        "dataset.info()\n",
        "\n",
        "\n",
        "# Langkah 3: Memisahkan Fitur (X) dan Target (y)\n",
        "# 'CLASS' adalah target (y), sisanya adalah fitur (X)\n",
        "X = dataset.drop('CLASS', axis=1)\n",
        "y = dataset['CLASS']\n",
        "\n",
        "\n",
        "# Langkah 4 & 5: Menangani Missing Values dan Encoding/Scaling dengan ColumnTransformer\n",
        "\n",
        "# Identifikasi tipe kolom\n",
        "numeric_features = ['AGE', 'BILIRUBIN', 'ALK_PHOSPHATE', 'SGOT', 'ALBUMIN', 'PROTIME']\n",
        "categorical_features = ['SEX', 'STEROID', 'ANTIVIRALS', 'FATIGUE', 'MALAISE', 'ANOREXIA',\n",
        "                        'LIVER_BIG', 'LIVER_FIRM', 'SPLEEN_PALPABLE', 'SPIDERS', 'ASCITES',\n",
        "                        'VARICES', 'HISTOLOGY']\n",
        "\n",
        "# Membuat pipeline preprocessing\n",
        "# Untuk data numerik: isi nilai kosong dengan rata-rata (mean), lalu lakukan scaling\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Untuk data kategorikal: isi nilai kosong dengan yang paling sering muncul (modus), lalu lakukan OneHotEncoding\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Gabungkan transformer menggunakan ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features), # Use the Pipeline object\n",
        "        ('cat', categorical_transformer, categorical_features) # Use the Pipeline object\n",
        "    ],\n",
        "    remainder='passthrough' # Biarkan kolom lain (jika ada) tidak diubah\n",
        ")\n",
        "\n",
        "\n",
        "# Terapkan ColumnTransformer ke X\n",
        "# Ini akan melakukan semua langkah (imputasi, scaling, encoding) sekaligus\n",
        "X = preprocessor.fit_transform(X)\n",
        "\n",
        "\n",
        "# Langkah 6: Encoding Label/Target (y)\n",
        "# Mengubah label DIE(1), LIVE(2) menjadi 0 dan 1\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "\n",
        "# Langkah 7: Membagi Dataset (Training & Test Set)\n",
        "# Membagi data menjadi 80% data latih dan 20% data uji\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Hasil Akhir\n",
        "print(\"\\n================ HASIL PREPROCESSING ================\")\n",
        "print(f\"Bentuk X_train: {X_train.shape}\")\n",
        "print(f\"Bentuk X_test: {X_test.shape}\")\n",
        "print(f\"Bentuk y_train: {y_train.shape}\")\n",
        "print(f\"Bentuk y_test: {y_test.shape}\")\n",
        "\n",
        "print(\"\\nContoh data X_train setelah preprocessing:\")\n",
        "print(X_train[:2])\n",
        "\n",
        "print(\"\\nContoh data y_train setelah encoding:\")\n",
        "print(y_train[:10])\n",
        "print(\"===================================================\")"
      ]
    }
  ]
}